{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from featurewiz import featurewiz\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "\n",
    "\n",
    "folder = os.path.join(\"/\", \"RanD\", \"CREMEv2_Result\", \"20230310\", \"logs_working\", \"label_traffic\")\n",
    "\n",
    "if os.path.exists(folder):\n",
    "    print(\"Path is exist!!!\")\n",
    "    filename_label = 'label_traffic.csv'\n",
    "    filename_ready = 'label_traffic_ready.csv'\n",
    "    filename_train = 'label_traffic_train.csv'\n",
    "    label_technique = 'labels_technique.json'\n",
    "    label_lifecycle = 'labels_lifecycle.json'\n",
    "else:\n",
    "    print(\"Path is not exist!!!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data processing and feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_with_hex_value = ['Sport', 'Dport']\n",
    "replace_strings = dict()\n",
    "remove_rows_with_str = dict()\n",
    "\n",
    "df = pd.read_csv(os.path.join(folder, filename_label), low_memory=False)\n",
    "\n",
    "\n",
    "# one-hot encoding\n",
    "# data = pd.get_dummies(data, columns=one_hot_col_list)\n",
    "\n",
    "# # string replacement\n",
    "for old_value, new_value in replace_strings.items():\n",
    "    df = df.replace(to_replace=old_value, value=new_value, regex=True)\n",
    "for old_value, new_value in remove_rows_with_str.items():\n",
    "    df = df.replace(to_replace=old_value, value=new_value)\n",
    "\n",
    "# preprocess hex value, str -> int\n",
    "for field in fields_with_hex_value:\n",
    "    df[field] = df[field].fillna(-1)\n",
    "    df[field] = df[field].apply(lambda x: x if type(x) is str else int(x))\n",
    "    df[field] = df[field].apply(lambda x: int(x, 0) if type(x) is str and x[:2] == \"0x\" else x)\n",
    "    # df[field] = df[field].apply(lambda x: int(str(x), 0))\n",
    "    df[field] = df[field].apply(lambda x: int(float(str(x))))\n",
    "\n",
    "\n",
    "# column name cleaning\n",
    "column_names = df.columns.values\n",
    "for i in range(len(column_names)):\n",
    "    column_names[i] = column_names[i].strip()\n",
    "df.columns = column_names\n",
    "\n",
    "df.info()\n",
    "\n",
    "# removing unused features from dataset\n",
    "target = \"Label\"\n",
    "\n",
    "feature, train = featurewiz(df, target, corr_limit=0.7, verbose=2, sep=\",\", header=0, test_data=\"\", feature_engg=\"\", category_encoders=\"\")\n",
    "df = train\n",
    "print(feature)\n",
    "output_filename = os.path.join(folder, filename_ready)\n",
    "df.to_csv(output_filename, encoding='UTF-8', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Training preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, Normalizer, QuantileTransformer, PowerTransformer\n",
    "\n",
    "df = pd.read_csv(os.path.join(folder, filename_ready))\n",
    "\n",
    "del_list = ['StartTime', 'Label_lifecycle']\n",
    "max_threshold = 100000\n",
    "min_threshold = 20\n",
    "\n",
    "print(\"origin data number: {0}\".format(len(df.index)))\n",
    "print(\"origin features: {0}\".format(len(df.columns)-1))\n",
    "\n",
    "df.drop(columns=del_list, inplace=True)\n",
    "\n",
    "for label in df['Label'].unique():\n",
    "    # if too much, try drop duplicated first\n",
    "    if len(df[df['Label'] == label]) > max_threshold:\n",
    "        df_tmp = df.loc[df['Label'] == label].copy()\n",
    "        df_tmp.drop_duplicates(keep='last', inplace=True)\n",
    "        df.drop(df[df['Label'] == label].index, inplace=True)\n",
    "        df = pd.concat([df, df_tmp])\n",
    "        \n",
    "    # if still too much, randomly picking some of them\n",
    "    if len(df[df['Label'] == label]) > max_threshold:\n",
    "        df_tmp = df.loc[df['Label'] == label].copy()\n",
    "        df_tmp = df_tmp.sample(n=max_threshold, random_state=47)\n",
    "        df.drop(df[df['Label'] == label].index, inplace=True)\n",
    "        df = pd.concat([df, df_tmp])\n",
    "\n",
    "    # if too few, double their number until it's enough\n",
    "    while len(df[df['Label'] == label]) < min_threshold:\n",
    "        tmp_df = df[df['Label'] == label]\n",
    "        df = pd.concat([df, tmp_df])\n",
    "\n",
    "\n",
    "# feature scaling\n",
    "y_tmp = df['Label']\n",
    "df.drop(columns=['Label'], inplace=True)\n",
    "for feature in df.columns.values:\n",
    "    scaler = StandardScaler().fit(df[feature].values.reshape(-1, 1))\n",
    "    df[feature] = scaler.transform(df[feature].values.reshape(-1, 1))\n",
    "df = pd.concat([df, y_tmp], axis=1)\n",
    "\n",
    "\n",
    "print(\"remain data number: {0}\".format(len(df.index)))\n",
    "print(\"remain features: {0}\".format(len(df.columns)-1))\n",
    "\n",
    "output_file = os.path.join(folder, filename_train)\n",
    "df.to_csv(output_file, encoding='utf-8', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, PassiveAggressiveClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import math\n",
    "\n",
    "models_folder = \"model_traffic\"\n",
    "\n",
    "df = pd.read_csv(os.path.join(folder, filename_train))\n",
    "\n",
    "#labelings map\n",
    "label_origin = sorted([int(i) for i in df['Label'].unique()])\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['Label'])\n",
    "le_origin_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "origin_le_mapping = dict(zip(le.transform(le.classes_), le.classes_))\n",
    "\n",
    "X = df.drop(columns=['Label'])\n",
    "X = X.to_numpy()\n",
    "y = df['Label']\n",
    "y = y.to_numpy()\n",
    "y = y.reshape(-1)\n",
    "y = le.transform(y)\n",
    "\n",
    "\n",
    "#ML training\n",
    "## Define ML model\n",
    "core = -1\n",
    "\n",
    "models = {}\n",
    "\n",
    "### Linear models\n",
    "models['Logistic_Regression'] = LogisticRegression(max_iter=1500, n_jobs=core)\n",
    "models['SGD'] = SGDClassifier(n_jobs=core)\n",
    "models['Passive_Aggressive'] = PassiveAggressiveClassifier(n_jobs=core)\n",
    "### non-linear models\n",
    "models['Decision_Tree'] = DecisionTreeClassifier()\n",
    "models['Extra_Tree'] = ExtraTreeClassifier()\n",
    "models['Naive_Bayes'] = GaussianNB()\n",
    "### models['SVM'] = SVC(kernel='rbf', gamma='auto')\n",
    "models['KNN'] = KNeighborsClassifier(n_jobs=core)\n",
    "### ensemble models\n",
    "models['Random_Forest'] = RandomForestClassifier(n_jobs=core)\n",
    "### models['Ada_Boost'] = AdaBoostClassifier()\n",
    "models['Bagging'] = BaggingClassifier(n_jobs=core)\n",
    "models['Extra_Trees'] = ExtraTreesClassifier(n_jobs=core)\n",
    "models['Gradient_Boosting'] = GradientBoostingClassifier()\n",
    "models['XGBoost'] = XGBClassifier(objective='multi:softprob', eval_metric='merror', n_jobs=core)\n",
    "\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "\n",
    "## training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
    "X_train, y_train = SMOTE(n_jobs=-1, random_state=random_seed).fit_resample(X_train, y_train)\n",
    "print(\"original labels:{}\".format(label_origin))\n",
    "print(\"X_train:{}, y_train:{}\".format(len(X_train), len(y_train)))\n",
    "\n",
    "\n",
    "evaluation = {}\n",
    "for name in models:\n",
    "    evaluation[name] = {\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1_score': []\n",
    "        # 'roc_auc_score': []\n",
    "    }\n",
    "\n",
    "    \n",
    "for name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    model_filename = os.path.join(models_folder, name)\n",
    "    if os.path.exists(model_filename): # load the model from disk\n",
    "        model = pickle.load(open(model_filename, 'rb'))\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        pickle.dump(model, open(model_filename, 'wb')) # save the model to disk\n",
    "    y_hat = model.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    print(\"model: {} \\nexecution time: {:.2f}\\n\".format(name, end_time - start_time))\n",
    "    \n",
    "    # evaluation\n",
    "    evaluation[name]['accuracy'].append(accuracy_score(y_test, y_hat,))\n",
    "    evaluation[name]['precision'].append(precision_score(y_test, y_hat, average='weighted',zero_division=0))\n",
    "    evaluation[name]['recall'].append(recall_score(y_test, y_hat, average='weighted', zero_division=0))\n",
    "    evaluation[name]['f1_score'].append(f1_score(y_test, y_hat, average='weighted', zero_division=0))\n",
    "    # evaluation[name]['roc_auc_score'].append(roc_auc_score(y, model.predict_proba(X)[:,1], multi_class='ovr'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Visualization Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "import pickle\n",
    "\n",
    "data_type = 'Nework Traffic'\n",
    "\n",
    "def rounded(value, n):\n",
    "    return math.floor(value * (10 ** n)) / float(10 ** n) \n",
    "\n",
    "models = [name.replace('_', '\\n') for name in evaluation]\n",
    "result = {\n",
    "    'accuracy': [],\n",
    "    'precision': [],\n",
    "    'recall': [],\n",
    "    'f1_score': []\n",
    "}\n",
    "for name in evaluation:\n",
    "    for key, value in evaluation[name].items():\n",
    "        result[key].append(rounded(mean(value), 3))\n",
    "        \n",
    "width = 0.2\n",
    "x = np.arange(len(models))\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(x, result['accuracy'], width, label='accuracy')\n",
    "plt.bar(x+width, result['precision'], width, label='precision')\n",
    "plt.bar(x+2*width, result['recall'], width, label='recall')\n",
    "bar = plt.bar(x+3*width, result['f1_score'], width, label='f1_score')\n",
    "plt.bar_label(bar, label_type='edge', fontsize=14)\n",
    "plt.title('Technique Model Evaluation for '+data_type, fontsize=30)\n",
    "plt.xticks(x+1.5*width, models)\n",
    "plt.xlabel('model', fontsize=14)\n",
    "plt.ylabel('value', fontsize=14)\n",
    "plt.rcParams.update({\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "})\n",
    "plt.legend(loc='center', fontsize=14, ncol=4, bbox_to_anchor=(0.5,-0.2))\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name = 'KNN'\n",
    "model_filename = os.path.join(models_folder, name)\n",
    "title = \"Technique Confusion Matrix of {} in {}\".format(name, data_type)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "target_names = label_origin\n",
    "# model = tf.keras.models.load_model(model_filename)\n",
    "model = pickle.load(open(model_filename, 'rb'))\n",
    "y_hat = model.predict(X_test)\n",
    "# y_hat = np.argmax(y_hat, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_hat)\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "ax = sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=target_names, yticklabels=target_names)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
    "ax.xaxis.tick_top()\n",
    "ax.xaxis.set_label_position('top')\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "plt.title(title, fontsize=20)\n",
    "plt.ylabel('Actual', fontsize=14)\n",
    "plt.xlabel('Predicted', fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show(block=False)\n",
    "\n",
    "# tree.export_graphviz(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
